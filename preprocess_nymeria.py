# å•å…ƒæ ¼: ã€è‡ªåŠ¨åŒ–ã€‘æŒ‰äººåæ‰¹é‡å¤„ç†ã€æå–è§†é¢‘å¹¶æ¸…ç†ç©ºé—´

import pandas as pd
import cv2
from pathlib import Path
import re
import numpy as np
import time
import shutil # ç”¨äºå®‰å…¨åˆ é™¤æ–‡ä»¶å¤¹
import wave
import subprocess
import os
from pathlib import Path
import tempfile
import json


# --- 1. ç”¨æˆ·é…ç½®åŒº ---
# â€¼ï¸ è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨åˆšåˆšä¸‹è½½å¹¶å¸Œæœ›å¤„ç†çš„äººå
PERSON_NAME_TO_PROCESS = "james_johnson"

# è¯·ç¡®è®¤æ‚¨çš„æ€»ä¸‹è½½ç›®å½•
DOWNLOADS_ROOT_DIR = Path("/content/drive/MyDrive/Colab Notebooks/Nymeria_Dataset/downloads")

# ã€å®‰å…¨å¼€å…³ã€‘è®¾ç½®ä¸º True æ¥å¯ç”¨è‡ªåŠ¨åˆ é™¤åŠŸèƒ½ã€‚
# å»ºè®®é¦–æ¬¡è¿è¡Œæ—¶ä¿æŒ Falseï¼Œç¡®è®¤è§†é¢‘æå–æ— è¯¯åå†è®¾ä¸º Trueã€‚
ENABLE_CLEANUP = False

# --- 2. å¯¼å…¥ Project Aria æ¨¡å— ---
try:
    from projectaria_tools.core.data_provider import create_vrs_data_provider
    from projectaria_tools.core.stream_id import StreamId
    from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions
    from projectaria_tools.core.vrs import extract_audio_track
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰å¿…éœ€çš„æ¨¡å—ã€‚")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥! è¯·å…ˆè¿è¡Œ '!pip install projectaria-tools'ã€‚é”™è¯¯: {e}")


# @title å•å…ƒæ ¼ 2: æ•°æ®å‡†å¤‡ (æ„å»º `datasets` å¯¹è±¡)
# --- 1. ç”¨æˆ·é…ç½®åŒº ---

# ã€å…³é”®ä¿®æ­£ã€‘æ›´æ–°ä¸ºæ‚¨å®é™…ä¸‹è½½å¹¶å¸Œæœ›å¤„ç†çš„å‚ä¸è€…å§“ååˆ—è¡¨
downloaded_participant_names = [
    'james_johnson', 'adriana_gonzalez', 'barbara_norman', 'christopher_martinez', 'frank_hayden',
    'david_hall', 'jacob_webb', 'hannah_brown', 'elizabeth_morgan', 'glenn_richardson', 'christopher_martinez'
]

# å®šä¹‰è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ’åˆ†æ¯”ä¾‹ï¼ˆä¾‹å¦‚ï¼Œ80%è®­ç»ƒï¼Œ20%æµ‹è¯•ï¼‰
TEST_SPLIT_RATIO = 0.3

# å®šä¹‰æ–‡ä»¶å’Œç›®å½•è·¯å¾„
DOWNLOADS_ROOT_DIR = Path("/content/drive/MyDrive/Colab Notebooks/Nymeria_Dataset/downloads")
# åˆ›å»ºä¸€ä¸ªæ€»çš„è¾“å‡ºç›®å½•æ¥å­˜æ”¾æ‰€æœ‰å¾®è°ƒç›¸å…³æ–‡ä»¶
OUTPUT_DATASET_DIR = DOWNLOADS_ROOT_DIR / "finetune_dataset_split"
OUTPUT_DATASET_DIR.mkdir(exist_ok=True)

# --- 2. æ£€æŸ¥å¹¶ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶ ---
train_metadata_file = OUTPUT_DATASET_DIR / "train_metadata.jsonl"
test_metadata_file = OUTPUT_DATASET_DIR / "test_metadata.jsonl"

# âœ… **å·²ä¿®å¤**: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è·³è¿‡ç”Ÿæˆæ­¥éª¤
if train_metadata_file.exists() and test_metadata_file.exists():
    print("âœ… è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ metadata.jsonl æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆæ­¥éª¤ã€‚")
else:
    print("â„¹ï¸  æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹ç”Ÿæˆ...")
    # --- æŒ‰å‚ä¸è€…å§“ååˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† ---
    print("â³ æ­£åœ¨æŒ‰å‚ä¸è€…å§“ååˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†...")
    random.seed(42)
    random.shuffle(downloaded_participant_names)
    num_test_participants = int(len(downloaded_participant_names) * TEST_SPLIT_RATIO)
    if num_test_participants == 0 and len(downloaded_participant_names) > 0:
        num_test_participants = 1
    test_participants = set(downloaded_participant_names[:num_test_participants])
    train_participants = set(downloaded_participant_names[num_test_participants:])
    print(f"âœ… åˆ’åˆ†å®Œæˆï¼")
    print(f"   - è®­ç»ƒé›†å‚ä¸è€… ({len(train_participants)}äºº): {train_participants}")
    print(f"   - æµ‹è¯•é›†å‚ä¸è€… ({len(test_participants)}äºº): {test_participants}")

    # --- éå†æ‰€æœ‰ä¸‹è½½çš„åºåˆ—ï¼Œå‡†å¤‡æ•°æ® ---
    print("\nâ³ å¼€å§‹éå†æ‰€æœ‰åºåˆ—æ–‡ä»¶å¤¹ï¼Œç”Ÿæˆæ•°æ®é›†...")
    train_data = []
    test_data = []
    all_sequence_folders = [f for f in DOWNLOADS_ROOT_DIR.iterdir() if f.is_dir()]
    instruction = "This is a first-person view video. Describe the main actions of the person in the third person in one sentence (e.g., 'The person walks down the hall and opens a door.')."

    for seq_dir in all_sequence_folders:
        try:
            parts = seq_dir.name.split('_')
            participant_name = f"{parts[2]}_{parts[3]}"
        except IndexError:
            print(f"âš ï¸ æ— æ³•ä»æ–‡ä»¶å¤¹å {seq_dir.name} è§£æå‚ä¸è€…ï¼Œå·²è·³è¿‡ã€‚")
            continue

        if participant_name in train_participants:
            target_list = train_data
        elif participant_name in test_participants:
            target_list = test_data
        else:
            continue

        video_clips_dir = seq_dir / "extracted_clips"
        csv_file_path = seq_dir / "narration/activity_summarization.csv"

        if not video_clips_dir.exists() or not csv_file_path.exists():
            continue

        annotations_df = pd.read_csv(csv_file_path)
        video_files = sorted(list(video_clips_dir.glob("*.mp4")))

        for video_path in video_files:
            match = re.search(r'activity_(\d+)_', video_path.name)
            if not match:
                continue
            activity_index = int(match.group(1))
            if activity_index < len(annotations_df):
                summary = annotations_df.iloc[activity_index]['Describe my activity']
                video_uri = f"file://{video_path.resolve()}"
                messages = [
                    {"role": "user", "content": [{"type": "video", "video": video_uri, "fps": 1}, {"type": "text", "text": instruction}]},
                    {"role": "assistant", "content": [{"type": "text", "text": summary}]}
                ]
                target_list.append({"messages": messages})

    print("\nâœ… æ‰€æœ‰åºåˆ—å¤„ç†å®Œæ¯•ï¼")

    # --- å°†æ•°æ®å†™å…¥ç‹¬ç«‹çš„ JSONL æ–‡ä»¶ ---
    with open(train_metadata_file, 'w') as f:
        for item in train_data:
            f.write(json.dumps(item) + '\n')
    print(f"ğŸ“ æˆåŠŸå†™å…¥è®­ç»ƒé›†æ–‡ä»¶: {train_metadata_file}ï¼ŒåŒ…å« {len(train_data)} æ¡è®°å½•ã€‚")

    with open(test_metadata_file, 'w') as f:
        for item in test_data:
            f.write(json.dumps(item) + '\n')
    print(f"ğŸ“ æˆåŠŸå†™å…¥æµ‹è¯•é›†æ–‡ä»¶: {test_metadata_file}ï¼ŒåŒ…å« {len(test_data)} æ¡è®°å½•ã€‚")

# --- 3. åŠ è½½ä¸º Hugging Face Dataset å¯¹è±¡ ---
if train_metadata_file.exists():
    try:
        train_dataset = Dataset.from_json(str(train_metadata_file))
        print("\nâœ… æˆåŠŸå°† train_metadata.jsonl åŠ è½½ä¸º Dataset å¯¹è±¡ã€‚")
        print(f"   - è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
        print("   - è®­ç»ƒé›†ç¤ºä¾‹:")
        print(train_dataset[0])
    except Exception as e:
        print(f"âŒ åŠ è½½è®­ç»ƒé›†æ—¶å‡ºé”™: {e}")
else:
    print("\nâŒ è®­ç»ƒé›†å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•åŠ è½½ã€‚")

if test_metadata_file.exists():
    try:
        test_dataset = Dataset.from_json(str(test_metadata_file))
        print("\nâœ… æˆåŠŸå°† test_metadata.jsonl åŠ è½½ä¸º Dataset å¯¹è±¡ã€‚")
        print(f"   - æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")
        print("   - æµ‹è¯•é›†ç¤ºä¾‹:")
        print(test_dataset[0])
    except Exception as e:
        print(f"âŒ åŠ è½½æµ‹è¯•é›†æ—¶å‡ºé”™: {e}")
else:
    print("\nâ„¹ï¸  æµ‹è¯•é›†å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œæœªåˆ›å»ºDatasetå¯¹è±¡ã€‚")


# --- 3. æŸ¥æ‰¾å±äºæŒ‡å®šäººç‰©çš„åºåˆ—æ–‡ä»¶å¤¹ ---
print(f"\nğŸ” æ­£åœ¨æ‰«æ {DOWNLOADS_ROOT_DIR} ...")
# æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æŒ‡å®šäººåçš„æ–‡ä»¶å¤¹
sequence_folders = [f for f in DOWNLOADS_ROOT_DIR.iterdir() if f.is_dir() and PERSON_NAME_TO_PROCESS in f.name]

if not sequence_folders:
    print(f"âŒ æœªæ‰¾åˆ°ä¸ '{PERSON_NAME_TO_PROCESS}' ç›¸å…³çš„ä»»ä½•åºåˆ—æ–‡ä»¶å¤¹ã€‚è¯·æ£€æŸ¥äººåæ˜¯å¦æ­£ç¡®æˆ–æ•°æ®æ˜¯å¦å·²ä¸‹è½½ã€‚")
else:
    print(f"âœ… æ‰¾åˆ° {len(sequence_folders)} ä¸ªä¸ '{PERSON_NAME_TO_PROCESS}' ç›¸å…³çš„åºåˆ—ï¼Œå‡†å¤‡å¼€å§‹å¤„ç†...")


for i, seq_dir in enumerate(sequence_folders):
    print(f"\n======================================================================")
    print(f"ğŸ¬ å¼€å§‹å¤„ç†åºåˆ— {i+1}/{len(sequence_folders)}: {seq_dir.name}")
    print("----------------------------------------------------------------------")

    vrs_file_path = seq_dir / "recording_head/data/data.vrs"
    csv_file_path = seq_dir / "narration/activity_summarization.csv"
    output_video_dir = seq_dir / "extracted_clips"
    output_video_dir.mkdir(parents=True, exist_ok=True)

    temp_audio_dir = Path(tempfile.mkdtemp())
    full_audio_path = temp_audio_dir / "full_audio.wav"

    if not vrs_file_path.exists() or not csv_file_path.exists():
        print(f"   - âŒ é”™è¯¯: ç¼ºå°‘VRSæˆ–CSVæ–‡ä»¶ï¼Œè·³è¿‡æ­¤åºåˆ—ã€‚")
        continue

    # --- æ­¥éª¤ 1: ä½¿ç”¨å®˜æ–¹å·¥å…· `extract_audio_track` æå–å®Œæ•´éŸ³è½¨ ---
    has_audio = False
    try:
        print(f"   - [æ­¥éª¤1] æ­£åœ¨ä½¿ç”¨å®˜æ–¹å·¥å…·æå–å®Œæ•´éŸ³è½¨...")
        json_output_string = extract_audio_track(str(vrs_file_path), str(full_audio_path))
        json_output = json.loads(json_output_string)
        if json_output and json_output.get("status") == "success":
            has_audio = True
            print(f"   - âœ… æˆåŠŸæå–å®Œæ•´éŸ³è½¨ã€‚")
        else:
            print(f"   - âš ï¸ è­¦å‘Š: å®˜æ–¹å·¥å…·æ— æ³•ä»æ­¤VRSæå–éŸ³è½¨ã€‚")
            print(f"     - å®˜æ–¹è¿”å›ä¿¡æ¯: {json_output_string}")
    except Exception as e:
        print(f"   - âŒ è°ƒç”¨ extract_audio_track æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

    # --- æ­¥éª¤ 2: æ‚¨çš„åŸå§‹é«˜æ•ˆæµç¨‹ï¼Œç”¨äºæå–è§†é¢‘å’Œåˆå¹¶ ---
    try:
        provider = create_vrs_data_provider(str(vrs_file_path))
        rgb_stream_id = provider.get_stream_id_from_label("camera-rgb")

        # è®¡ç®—FPS
        num_frames_total = provider.get_num_data(rgb_stream_id)
        fps = 15 if num_frames_total < 10 else int(round(1.0 / np.mean(np.diff([provider.get_image_data_by_index(rgb_stream_id, j)[1].capture_timestamp_ns for j in range(min(100, num_frames_total))]) / 1e9)))
        print(f"   - ğŸ–¼ï¸  è®¡ç®—è§†é¢‘å¸§ç‡ä¸º {fps} FPSã€‚")

        annotations_df = pd.read_csv(csv_file_path)
        print(f"   - [æ­¥éª¤2] åŠ è½½äº† {len(annotations_df)} ä¸ªæ´»åŠ¨æ³¨é‡Šï¼Œå¼€å§‹å¿«é€Ÿæå–å’Œåˆå¹¶...")

        for index, activity in annotations_df.iterrows():
            start_sec = activity['start_time']
            end_sec = activity['end_time']
            duration_sec = end_sec - start_sec
            activity_description = activity['Describe my activity']
            start_time_ns, end_time_ns = int(start_sec * 1e9), int(end_sec * 1e9)

            start_index_vid = provider.get_index_by_time_ns(rgb_stream_id, start_time_ns, TimeDomain.DEVICE_TIME, TimeQueryOptions.AFTER)
            end_index_vid = provider.get_index_by_time_ns(rgb_stream_id, end_time_ns, TimeDomain.DEVICE_TIME, TimeQueryOptions.BEFORE)

            if start_index_vid >= end_index_vid:
                continue

            safe_desc = re.sub(r'[^a-zA-Z0-9_]', '', activity_description.replace(' ', '_'))[:30]
            base_filename = f"activity_{index:03d}_{safe_desc}"
            temp_video_path = output_video_dir / f"{base_filename}_temp_video.mp4"
            final_output_path = output_video_dir / f"{base_filename}.mp4"

            # æå–æ— å£°è§†é¢‘
            first_frame = provider.get_image_data_by_index(rgb_stream_id, start_index_vid)[0].to_numpy_array()
            h, w, _ = cv2.rotate(first_frame, cv2.ROTATE_90_CLOCKWISE).shape
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            video_writer = cv2.VideoWriter(str(temp_video_path), fourcc, fps, (w, h))
            for frame_idx in range(start_index_vid, end_index_vid + 1):
                img_rgb = provider.get_image_data_by_index(rgb_stream_id, frame_idx)[0].to_numpy_array()
                video_writer.write(cv2.cvtColor(cv2.rotate(img_rgb, cv2.ROTATE_90_CLOCKWISE), cv2.COLOR_RGB2BGR))
            video_writer.release()

            # ä½¿ç”¨ FFmpeg è¿›è¡Œæœ€ç»ˆåˆå¹¶
            if has_audio:
                command = [
                    'ffmpeg', '-y', '-i', str(temp_video_path), '-ss', str(start_sec),
                    '-i', str(full_audio_path), '-t', str(duration_sec),
                    '-c:v', 'copy', '-c:a', 'aac', '-b:a', '192k', str(final_output_path)
                ]
                subprocess.run(command, capture_output=True, text=True, check=True)
                os.remove(temp_video_path)
                print(f"     - âœ… æˆåŠŸåˆå¹¶éŸ³è§†é¢‘: {final_output_path.name}")
            else:
                os.rename(temp_video_path, final_output_path)
                print(f"     - âœ… å·²ä¿å­˜æ— å£°è§†é¢‘: {final_output_path.name}")

    except Exception as e:
        print(f"   - âŒ å¤„ç†åºåˆ— {seq_dir.name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    finally:
        if temp_audio_dir.exists():
            shutil.rmtree(temp_audio_dir)

print(f"\n\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰ä¸ '{PERSON_NAME_TO_PROCESS}' ç›¸å…³çš„åºåˆ—å¤„ç†å®Œæ¯•ï¼ğŸ‰ğŸ‰ğŸ‰")
